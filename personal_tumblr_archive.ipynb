{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903afc79-5076-44b4-8bb1-aebfd16152a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Set Up to use Tumblr API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684809d-8847-4a6a-ab50-ee3f297d3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytumblr pyyaml rauth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba3a94-1ba4-4b5a-b860-c6521d7715b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8e4e7-2840-4361-b4e0-72147283cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytumblr\n",
    "import os\n",
    "import yaml\n",
    "import webbrowser\n",
    "from rauth import OAuth1Service\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, parse_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61148a-9523-4cd3-995f-f6343596a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad046eb0-95b2-4b69-84e2-c9e78d47ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Tumblr App credentials\n",
    "consumer_key = \"<consumer_key>\"\n",
    "consumer_secret = \"<consumer_secret>\"\n",
    "\n",
    "# Token storage path\n",
    "tumblr_token_path = Path.home() / \".tumblr\"\n",
    "\n",
    "# Function to load tokens from file\n",
    "def load_tokens():\n",
    "    if tumblr_token_path.exists():\n",
    "        with open(tumblr_token_path, \"r\") as f:\n",
    "            return yaml.safe_load(f)\n",
    "    return None\n",
    "\n",
    "# Function to save tokens to file\n",
    "def save_tokens(tokens):\n",
    "    with open(tumblr_token_path, \"w\") as f:\n",
    "        yaml.dump(tokens, f)\n",
    "    print(f\"Tokens saved to {tumblr_token_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04776ff2-bf75-4488-9d6f-6ed30b3dee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_oauth():\n",
    "    tumblr = OAuth1Service(\n",
    "        name='tumblr',\n",
    "        consumer_key=consumer_key,\n",
    "        consumer_secret=consumer_secret,\n",
    "        request_token_url='https://www.tumblr.com/oauth/request_token',\n",
    "        access_token_url='https://www.tumblr.com/oauth/access_token',\n",
    "        authorize_url='https://www.tumblr.com/oauth/authorize',\n",
    "        base_url='https://api.tumblr.com/v2/'\n",
    "    )\n",
    "    # Step 1: Get request token\n",
    "    request_token, request_token_secret = tumblr.get_request_token(params={'oauth_callback': 'http://www.example.com'})\n",
    "    authorize_url = tumblr.get_authorize_url(request_token) \n",
    "\n",
    "    print(\"Go to this URL and authorize the app:\")\n",
    "    print(authorize_url)\n",
    "\n",
    "    webbrowser.open(authorize_url)\n",
    "\n",
    "    verifier = input(\"Paste the verifier Tumblr shows you: \").strip()\n",
    "\n",
    "    session = tumblr.get_auth_session(request_token, request_token_secret,\n",
    "                                 method='POST', data={'oauth_verifier': verifier})\n",
    "     # Print the oauth_token and oauth_token_secret\n",
    "    print(\"OAuth Token:\", session.access_token)\n",
    "    print(\"OAuth Token Secret:\", session.access_token_secret)\n",
    "\n",
    "    return {\n",
    "        'consumer_key': consumer_key,\n",
    "        'consumer_secret': consumer_secret,\n",
    "        'oauth_token': session.access_token,\n",
    "        'oauth_token_secret': session.access_token_secret\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234dec2-7b85-41c6-ae1f-5d2b5907e08e",
   "metadata": {},
   "source": [
    "__After running the snippet below, and authorizing the app, the verifier is found in the URL after 'oauth_verifier='__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96c052-7837-41f8-a210-1fdb91e9ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = do_oauth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3037e92f-5af9-432b-9281-659777a741ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Corpus Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54127ab9-0554-4de6-bb5d-06e75f62dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in these to make it easier to use again\n",
    "consumer_key = '<consumer_key>'\n",
    "consumer_secret = '<consumer_secret>'\n",
    "oauth_token = '<oauth_token>'\n",
    "oauth_token_secret = '<oauth_secret>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a787e-ebdb-4737-b907-3c0adfa1aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pytumblr.TumblrRestClient(\n",
    "    '<consumer_key>',\n",
    "    '<consumer_secret>',\n",
    "    '<oauth_token>',\n",
    "    '<oauth_secret>',\n",
    ")\n",
    "\n",
    "blog_name = '<replace with link to tumblr page>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0662411-213e-4132-b546-b57d066a4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44d4de-f78c-4392-95a3-edc42093bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c44e0-c48e-4737-a7d2-789f85ba6f4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Compile and Preprocess Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298d406-0e44-4ac6-9cd2-f665e6590325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this function to collect posts by month\n",
    "#month param should be an int 1-12\n",
    "def collect_monthly_posts(blog_name, consumer_key, year, month, limit=20):\n",
    "    offset = 0\n",
    "    posts_collected = []\n",
    "\n",
    "    # Calculate start and end timestamps for the specified month\n",
    "    start_date = int(datetime(year, month, 1).timestamp())\n",
    "    if month == 12:\n",
    "        end_date = int(datetime(year + 1, 1, 1).timestamp())\n",
    "    else:\n",
    "        end_date = int(datetime(year, month + 1, 1).timestamp())\n",
    "\n",
    "    def collect_posts(offset):\n",
    "        request_uri = (\n",
    "            f\"https://api.tumblr.com/v2/blog/{blog_name}/posts\"\n",
    "            f\"?api_key={consumer_key}&limit={limit}&offset={offset}\"\n",
    "        )\n",
    "        response = requests.get(request_uri)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    while True:\n",
    "        data = collect_posts(offset)\n",
    "        posts = data['response'].get('posts', [])\n",
    "\n",
    "        if not posts:\n",
    "            break\n",
    "\n",
    "        for post in posts:\n",
    "            post_date_str = post['date']\n",
    "            post_date = datetime.strptime(post_date_str[:-4], \"%Y-%m-%d %H:%M:%S\")\n",
    "            post_timestamp = int(post_date.timestamp())\n",
    "\n",
    "            if start_date <= post_timestamp < end_date:\n",
    "                posts_collected.append(post)\n",
    "        \n",
    "        offset += limit\n",
    "\n",
    "    return pd.DataFrame(posts_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd44df-dce5-4e80-bce5-d780650c79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframes into variables\n",
    "month_df = collect_monthly_posts(blog_name, consumer_key, 2025, month, limit=20)\n",
    "#eg: jan_df = collect_monthly_posts(blog_name, consumer_key, 2025, 1, limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda5395-a125-4072-b5fc-479172e60a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list columns in df\n",
    "list(month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6559aa8-ddf6-44ac-8d4b-6b6b765e6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['date','id', 'post_url','tags', 'body'] #adapt for your purposes\n",
    "month_posts = month_df[columns_to_keep]\n",
    "month_posts = month_posts.sort_values(by='date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e620c9b-8cfa-4654-abd1-93e2f9bb4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all dfs needed\n",
    "posts_df = [month1_posts, month2_posts, month3_posts]\n",
    "df = pd.concat(posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd9739-20c2-4a57-888e-5d2aa8389fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e900ef1-9ca0-43df-98fa-2f5dd53f1376",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac02c3-af98-4f35-b984-beec9b85a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the following if/when needed or combine to create a multi-step preprocess function\n",
    "def html_to_text(x):\n",
    "    if isinstance(x, str) and ('<' in x and '>' in x):  # crude check for HTML\n",
    "        return BeautifulSoup(x, 'html.parser').get_text()\n",
    "    return x  # return as-is if not HTML\n",
    "\n",
    "def remove_punc(text):\n",
    "    punctuation = '!@#$%^&*()_+={}[]:;\"\\'|<>,.?/~`'\n",
    "    text = ''.join(character for character in text if character not in punctuation) \n",
    "    return text\n",
    "\n",
    "#for removing user links and names while before removing html\n",
    "def remove_users(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = ''  # or str(text) if you want to preserve the original content\n",
    "\n",
    "    # Remove all <a ...>username</a>: patterns\n",
    "    cleaned = re.sub(r'<a[^>]*>[^<]*</a>:', '', text)\n",
    "\n",
    "    # Repeat in case of multiple user links\n",
    "    while re.search(r'<a[^>]*>[^<]*</a>:', cleaned):\n",
    "        cleaned = re.sub(r'<a[^>]*>[^<]*</a>:', '', cleaned)\n",
    "    text = cleaned.strip()\n",
    "    return text\n",
    "\n",
    "def del_urls(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags = re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "def del_htmltags(text):\n",
    "    text = re.sub(r'<.*?>', '', text) \n",
    "    return text\n",
    "    \n",
    "def rem_allhtml(text):\n",
    "    if pd.isna(text):\n",
    "        return ''  # Return empty string for NaN or None\n",
    "    else:\n",
    "        return BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "def del_emoj(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # Remove emojis and other non-ASCII characters\n",
    "    else: \n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8456e-5c81-46a0-b668-639683521160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply preprocess\n",
    "df['body'] = df['body'].apply(remove_users)\n",
    "df['body'] = df['body'].apply(html_to_text)\n",
    "df['body'] = df['body'].str.replace('\\n', ' ', regex=False).str.replace('\\r', ' ', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12eb6f-67b8-451f-98f0-682bb6300a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove posts to be excluded from dataset for analysis\n",
    "#remove posts tagged \"not thg\" \n",
    "df = df[~df['tags'].apply(lambda tags: 'not thg' in tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e899a5-d318-4e70-ba77-579fb8764234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save archive as CSV\n",
    "df.to_csv('blog_archive.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf946b9-0227-46bb-9257-f7e1afe470d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tag Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7cc1b-d717-474e-8aaa-7a1d463bf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine/use alias maps to combine tags that mean the same - adapt for usage\n",
    "alias_map = {\n",
    "    'katniss': 'katniss everdeen',\n",
    "    'katniss everdeen': 'katniss everdeen',\n",
    "    'thg katniss': 'katniss everdeen',\n",
    "    'peeta mellark': 'peeta mellark',\n",
    "    'peeta': 'peeta mellark',\n",
    "    'thg peeta': 'peeta mellark',\n",
    "    'katniss x peeta': 'everlark',\n",
    "    'peeta x katniss': 'everlark',\n",
    "    'Everlark': 'everlark',\n",
    "    'haymitch': 'haymitch abernathy',\n",
    "    'haymitch abernathy': 'haymitch abernathy',\n",
    "    'finnick': 'finnick odair',\n",
    "    'finnick odair': 'finnick odair',\n",
    "    'thg finnick': 'finnick odair',\n",
    "    'gale hawthorne': 'gale hawthorne',\n",
    "    'gale': 'gale hawthorne',\n",
    "    'hunger games': 'the hunger games',\n",
    "    'the hunger games': 'the hunger games'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc20db-f5c1-4729-a175-497a6fa7bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_tag_count(df):\n",
    "    # Convert string representation of lists into actual Python lists\n",
    "    df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    all_tags = [tag for tags in df['tags'] for tag in tags]\n",
    "    all_tags = [tag.lower() for tag in all_tags]\n",
    "    tag_counts = Counter(all_tags)\n",
    "    return tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a78e07-909b-4acf-9713-41d706e7d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to compile individual dfs for each theme/character/tag eg: 'talking about characters'\n",
    "def extract_character(df, tag):\n",
    "    tag_df = df[df['tags'].apply(lambda tags: tag in tags if isinstance(tags, list) else False)]\n",
    "    tag_df.reset_index(drop=True, inplace=True)\n",
    "    return tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df793aaa-5275-4529-bd89-11b232d92681",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_df = extract_character(df_characters, 'character')\n",
    "#eg: katniss_df = extract_character(df_characters, 'katniss everdeen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e34ad-1c9a-43fd-baa4-ec417a4257fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters.to_csv('phase1_characters.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda8618-c076-48ec-9b16-681b81a433fa",
   "metadata": {},
   "source": [
    "# Riveter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c937240-3530-4dca-b767-e34b3583035c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39afd0-5928-4f1a-937b-07845427fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for riveter\n",
    "!pip install -U spacy-experimental\n",
    "!pip install https://github.com/explosion/spacy-experimental/releases/download/v0.6.0/en_coreference_web_trf-3.4.0a0-py3-none-any.whl\n",
    "#egg=en_coreference_web_trf\n",
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda85211-48ec-4007-a46e-400383f253ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd #to confirm directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e92a2-1c59-42c4-b766-2050df72fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f2034-6ad4-4814-9e8e-d6fcce9faa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just in case it was missed earlier\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b0b424-c32f-4c95-8af0-0623031039f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACY & COREF IMPORTS\n",
    "import spacy\n",
    "import spacy_experimental\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp_coref = spacy.load(\"en_coreference_web_trf\")\n",
    "\n",
    "nlp_coref.replace_listeners(\"transformer\", \"coref\", [\"model.tok2vec\"])\n",
    "nlp_coref.replace_listeners(\"transformer\", \"span_resolver\", [\"model.tok2vec\"])\n",
    "\n",
    "nlp.add_pipe(\"coref\", source=nlp_coref)\n",
    "nlp.add_pipe(\"span_resolver\", source=nlp_coref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30397b-d43c-41c0-b5b3-04787b4dfdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from riveter import Riveter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b2890-6648-4dff-8ec8-8831251128b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for preprocessing text\n",
    "from bs4 import BeautifulSoup\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60b469-d4a0-46f4-ab58-994ad6ce8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_1_corpus = character_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4c0af-25a9-4641-98af-1ae57e28277e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf7a72-6043-4e63-aea9-164f6aebbce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['post_id', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e740c-c0ac-4e35-9843-4e0481030320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dicts to a list of values from the dictionary\n",
    "def dict_val_to_list(my_dict):\n",
    "  if not isinstance(my_dict, dict):\n",
    "    print(\"Error: Input is not a dictionary.\")\n",
    "    return []  # Return an empty list if the input is not a dictionary\n",
    "\n",
    "  return list(my_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c22cf-eca2-426f-ab87-79d1ae760866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_list(html_list):\n",
    "    cleaned = []\n",
    "    for item in html_list:\n",
    "        if not isinstance(item, str):\n",
    "            # Option 1: convert to string\n",
    "            item = str(item)\n",
    "            # Option 2: skip non-string items by uncommenting the next line\n",
    "            # continue\n",
    "        soup = BeautifulSoup(item, 'html.parser')\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "        text = re.sub(r'\\xa0', '', text)\n",
    "        cleaned.append(text)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e215b-e799-4583-a5e2-3c872419de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = phase_1_corpus[keep_columns]\n",
    "p1_id_dict = p1['post_id'].to_dict()\n",
    "p1_ids = dict_val_to_list(p1_id_dict)\n",
    "p1_body_dict = p1['text'].to_dict()\n",
    "p1_text = dict_val_to_list(p1_body_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea156435-0c8e-4be0-83e7-9dfd92fa5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_texts = parse_html_list(p1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cd7e4-8c0b-422b-82b5-e08c5840789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this dict like an alias map - use regex so model is trained to recognize different ways of naming a character\n",
    "persona_patterns_dict={'katniss': r'^katniss$|^katniss everdeen$|^girl on fire$',\n",
    "                        'peeta': r'^peeta$|^peeta mellark$|^boy with the bread$',\n",
    "                        'haymitch': r'^haymitch$|^haymitch abernathy$',\n",
    "                        'president snow': r'^coryo$|^snow$|^president snow$|^coriolanus snow$',\n",
    "                        'president coin': r'^coin$|^alma coin$|^president coin$|^d13 president$',\n",
    "                        'primrose': r'^prim$|^primrose$|^primrose everdeen$',\n",
    "                        'gale': r'^gale$|^gale hawthorne$', \n",
    "                        'finnick': r'^finnick$|^finnick odair$',\n",
    "                        'plutarch': r'^plutarch$|^plutarch heavensbee$',\n",
    "                        'annie': r'^annie$|^annie cresta$',\n",
    "                        'johanna': r'^johanna$|^johanna mason$',\n",
    "                        'rue': r'^rue$',\n",
    "                        'effie': r'^effie$|^effie trinket$',\n",
    "                        'capitol': r'^the capitol$|^capitol$|^the rich$|^the wealthy$|^government$',\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4d224-56b4-4d25-a193-d92c0f4e0b8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load and Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13613045-13ff-49d7-b22f-7ba1236babdb",
   "metadata": {},
   "source": [
    "Choose between riveter.load_sap_lexicon('agency') and riveter.load_sap_lexicon('power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd6d16-2542-4b38-91e2-41f45700f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "riveter = Riveter()\n",
    "riveter.load_sap_lexicon('power') \n",
    "#when doing for my data - the arguments will be (body, ids) where ids = df['id']\n",
    "riveter.train(p1_texts, p1_ids,\n",
    "              persona_patterns_dict={'katniss': r'^katniss$|^katniss everdeen$|^girl on fire$',\n",
    "                        'peeta': r'^peeta$|^peeta mellark$|^boy with the bread$',\n",
    "                        'haymitch': r'^haymitch$|^haymitch abernathy$',\n",
    "                        'president snow': r'^coryo$|^snow$|^president snow$|^coriolanus snow$',\n",
    "                        'president coin': r'^coin$|^alma coin$|^president coin$|^d13 president$',\n",
    "                        'primrose': r'^prim$|^primrose$|^primrose everdeen$',\n",
    "                        'gale': r'^gale$|^gale hawthorne$', \n",
    "                        'finnick': r'^finnick$|^finnick odair$',\n",
    "                        'plutarch': r'^plutarch$|^plutarch heavensbee$',\n",
    "                        'annie': r'^annie$|^annie cresta$',\n",
    "                        'johanna': r'^johanna$|^johanna mason$',\n",
    "                        'rue': r'^rue$',\n",
    "                        'effie': r'^effie$|^effie trinket$',\n",
    "                        'capitol': r'^the capitol$|^capitol$|^the rich$|^the wealthy$|^government$',\n",
    "                       }\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b1153-44fc-4699-9c92-2778c0c8eb89",
   "metadata": {},
   "source": [
    "Check documentation, or myriv-test to see options for explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7db51b-8810-4e44-959f-3f6ec77a2b03",
   "metadata": {},
   "source": [
    "Load riveter.load_rashkin_lexicon('dimension') and choose from different available dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be1ddd-a765-4c41-8ae1-046f49ddeb85",
   "metadata": {},
   "source": [
    "#### Connotation Frames available via Rashkin: \n",
    "- __effect__: whether the event denoted by a predicate is good or bad for the entity\n",
    "- __state__: the likely mental state of an entity as the result of an event\n",
    "- __value__: whether an entity is presupposed to be valuable\n",
    "- __writer_perspective__/__reader_perspective__: the directed sentiment from the writer to an entity or the _predicted_ directed sentiment from reader to an entity\n",
    "- __agent_theme_perspective__/__theme_agent_perspective__: the directed sentiment between the agent and theme (usually reciprocal and not likely to totally contradict each other). \n",
    "\n",
    "Connotation frame polarity can be positive, negative, or neutral. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30557df-ec98-4ceb-9750-ef81ba7b2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "riveter = Riveter()\n",
    "riveter.load_sap_lexicon('dimension')\n",
    "riveter.train(p2_texts,\n",
    "              p2_ids,\n",
    "              persona_patterns_dict={'katniss': r'^katniss$|^katniss everdeen$|^girl on fire$',\n",
    "                        'peeta': r'^peeta$|^peeta mellark$|^boy with the bread$',\n",
    "                        'haymitch': r'^haymitch$|^haymitch abernathy$',\n",
    "                        'president snow': r'^coryo$|^snow$|^president snow$|^coriolanus snow$',\n",
    "                        'president coin': r'^coin$|^alma coin$|^president coin$|^d13 president$',\n",
    "                        'primrose': r'^prim$|^primrose$|^primrose everdeen$',\n",
    "                        'gale': r'^gale$|^gale hawthorne$', \n",
    "                        'finnick': r'^finnick$|^finnick odair$',\n",
    "                        'plutarch': r'^plutarch$|^plutarch heavensbee$',\n",
    "                        'annie': r'^annie$|^annie cresta$',\n",
    "                        'johanna': r'^johanna$|^johanna mason$',\n",
    "                        'rue': r'^rue$',\n",
    "                        'effie': r'^effie$|^effie trinket$',\n",
    "                        'capitol': r'^the capitol$|^capitol$|^the rich$|^the wealthy$|^government$',\n",
    "                       }\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f782e-e30d-41a8-b4fd-139d6abffd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
